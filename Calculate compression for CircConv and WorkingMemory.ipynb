{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate compression for WorkingMemory module\n",
    "This notebook is used to calculate the compression ratio and 10 other statistics for a preprocessed SPAUN WorkingMemory module. The module is one of several used in the SPAUN model and is used in this notebook to illustrate the compression we can achieve with SPAUN. \n",
    "\n",
    "When calculating the statistics for a single preprocessed SPAUN module, bear in mind, the modules inputs and outputs from other modules may not be instantiated and, therefore, the Nodes and Ensembles in WorkingMemory may not be connected to Nodes and Ensembles from other modules. If this is the case, preprocessing can eliminate Nodes if the Nodes have no input connection as well as encoding or decoding Ensemble weights if the Ensemble has no input or output connection respectively. If a Node or encoding/decoding weight is eliminated, the statistics (e.g. the total encoding weights) are smaller than they would be when the WorkingMemory module is instantiated in a full SPAUN module. \n",
    "\n",
    "The following sections\n",
    "- provide formulas for the compression ratio and the 10 other statistics we are interested, \n",
    "- provide statistics for a preprocessed SPAUN WorkingMemory module with 512-dimensional semantic pointers.\n",
    "- verify the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "This section provides formulas for the the statistics we are interested in. The formulas use the following four variables. \n",
    "\n",
    "$D$ = semantic pointer dimensions\n",
    "\n",
    "$k_1$  = number of neurons per Ensemble dimension\n",
    "\n",
    "$k_2$ = number of neurons per Ensemble dimension\n",
    "\n",
    "$d_1$ = input/output dimensions of an Ensemble \n",
    "\n",
    "The variable $D$ is provided to Nengo when instantiating SPAUNs WorkingMemory module. The variables $k_1$, $k_2$ and $d_1$ are not provided by the user during instantiation but are contained in the Nengo algorithms which instantiate and preprocess the WorkingMemory module.\n",
    "\n",
    "The 11 statistics we are interested in are as follows.\n",
    "\n",
    "### Total decoding weights\n",
    "The total number of decoding weights is calculated as follows:<br><br>\n",
    "\n",
    "$$\n",
    "N_\\text{D} = (73 + \\frac{59D}{d_1})k_1d_1^2 + 3k_2d_1^2\n",
    "$$\n",
    "\n",
    "\n",
    "### Total encoding weights\n",
    "The total number of encoding weights is calculated as follows:<br><br>\n",
    "\n",
    "$$\n",
    "N_\\text{E} = (63 + \\frac{95D}{d_1})k_1d_1^2 + 3k_2d_1^2\n",
    "$$\n",
    "\n",
    "### Total transform resource count\n",
    "The total transform resource count is calculated as follows:<br><br>\n",
    "\n",
    "$$\n",
    "N_\\text{T} =\n",
    "\\begin{cases}\n",
    "(212D+9) + 3D^2 + 24 & \\text{if }  D==2 \\text{ or } D==3 \\text{ or } D==4 \\\\\n",
    "(212D+9) + 6(D-3)(D-4) + 3D^2 + 24 & \\text{if } D < 2 \\text{ or } D > 4\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Note that the last two terms are due to Bias nodes that in the module that grow with dimensions D and are not part of a connection path between Ensembles. Therefore, we will not see these terms in the equations for synaptics weight or fanout.\n",
    "\n",
    "### Total number of synapses\n",
    "The total number of synapses is calculated as follows:<br><br>\n",
    "\n",
    "$$\n",
    "N_\\text{SYN}=\n",
    "\\begin{cases}\n",
    "(206D+9)(k_1d_1)^2 + 6Dk_1k_2d_1^2 & \\text{if }D==2, D==3, D==4 \\\\\n",
    "(206D+9)(k_1d_1)^2 + 6Dk_1k_2d_1^2 + 6(D-3)(D-4)(k_1d_1)^2 & \\text{if }D < 2 \\text{ or } D > 4\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### Compression ratio\n",
    "The compression ratio is calculated as follows:<br><br>\n",
    "\n",
    "$$C=\\frac{N_\\text{E}+N_\\text{D}+N_\\text{T}}{N_\\text{SYN}}$$\n",
    "\n",
    "### Total number of neurons\n",
    "The total number of neurons is calculated as follows:<br><br>\n",
    "\n",
    "$$\n",
    "N_\\text{NRN} = (73 + \\frac{52D}{d_1})k_1d_1 + 3k_2d_1\n",
    "$$\n",
    "\n",
    "### Total number of ensembles\n",
    "The total number of ensembles is calculated as follows:<br><br>\n",
    "\n",
    "$$\n",
    "N_\\text{ENS} = 76 + \\frac{58D}{d_1}\n",
    "$$\n",
    "\n",
    "### Fanout\n",
    "\n",
    "The total fanout is calculated as follows:<br><br>\n",
    "\n",
    "$$\n",
    "N_\\text{SYN}=\n",
    "\\begin{cases}\n",
    "(212D+9) & \\text{if }D==2, D==3, D==4 \\\\\n",
    "(212D+9) + 6(D-3)(D-4) & \\text{if }D < 2 \\text{ or } D > 4\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### Neurons per ensemble\n",
    "The ratio of neurons to ensembles is defined as:<br><br>\n",
    "\n",
    "$$R_\\text{NRN-ENS}=\\frac{N_\\text{NRN}}{N_\\text{ENS}}$$\n",
    "\n",
    "###Synapses per neurons\n",
    "The ratio of synapses to neurons is defined as:<br><br>\n",
    "\n",
    "$$R_\\text{SYN-NRN}=\\frac{N_\\text{SYN}}{N_\\text{NRN}}$$\n",
    "\n",
    "### Average fanout\n",
    "\n",
    "$$R_\\text{FAN-ENS}=\\frac{N_\\text{FAN}}{N_\\text{ENS}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working memory module with 512-D semantic pointers\n",
    "\n",
    "We can now evaluate the compression ratio for the WorkingMemory module in SPAUN. Given that the number of dimensions D is 512, input/output dimensions of every Ensemble $d_1$ is 1 and the constant $k_2$ is equal to $\\frac{2}{5}k_1$, we can use those values to simplify the equations $N_\\text{D}$, $N_\\text{E}$, $N_\\text{T}$ and $N_\\text{SYN}$ as follows.\n",
    "\n",
    "For the equation $N_\\text{D}$, we replace $k_2$ and $d_1$ and re-factor, getting \n",
    "\n",
    "$$\n",
    "N_\\text{D} = (74.2 + 59D)k_1\n",
    "$$\n",
    "\n",
    "For the equation $N_\\text{E}$, we again replace $k_2$ and $d_1$ and re-factor, getting \n",
    "\n",
    "$$\n",
    "N_\\text{E} = (64.2 + 95D)k_1\n",
    "$$\n",
    "\n",
    "For the equation $N_\\text{T}$, since $D == 512$, we choose the second case, getting \n",
    "\n",
    "$$\n",
    "N_\\text{T} = (212D + 9) + 6(D-3)(D-4) + 3D^2 + 24\n",
    "$$\n",
    "\n",
    "For reasons that will become clear shortly, let's expand $N_\\text{T}$ getting\n",
    "\n",
    "$$\n",
    "N_\\text{T} = 9D^2 + 170D + 105\n",
    "$$\n",
    "\n",
    "For equation $N_\\text{SYN}$, since $D == 512$, we choose the second case, replace $k_2$ and $d_1$, and refactor, getting\n",
    "\n",
    "$$\n",
    "N_\\text{SYN} = ((208.4D+9) + 6(D-3)(D-4))k_1^2\n",
    "$$\n",
    "\n",
    "We'll expand $N_\\text{SYN}$ as we did for $N_\\text{T}$ getting\n",
    "\n",
    "$$\n",
    "N_\\text{SYN} = (6D^2 + 166.4D + 81)k_1^2\n",
    "$$\n",
    "\n",
    "Finally, the equation $C$ is composed of the first three equations in the numerator and the last equation in the denominator. I'll write $C$ as a summation of the three terms getting\n",
    "\n",
    "$$\n",
    "C = \\frac{(74.2 + 59D)k_1}{(6D^2 + 166.4D + 81)k_1^2 } + \\frac{(64.2 + 95D)k_1}{(6D^2 + 166.4D + 81)k_1^2} + \\frac{9D^2 + 170D + 105}{(6D^2 + 166.4D + 81)k_1^2}\n",
    "$$\n",
    "\n",
    "Simplifying\n",
    "\n",
    "$$\n",
    "C = \\frac{(74.2 + 59D)}{(6D^2 + 166.4D + 81)}\\frac{1}{k_1} + \\frac{(64.2 + 95D)}{(6D^2 + 166.4D + 81)}\\frac{1}{k_1} + \\frac{9D^2 + 170D + 105}{(6D^2 + 166.4D + 81)}\\frac{1}{k_1^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice two things about compression with this module. First, the synaptics weight count grows quadratically with respect to semantic pointer dimensions. Second, the encoder and decoder weights in the first two terms grow linearly whereas the transform resource count in the third term grows quadratically with respect to semantic pointer dimensions. Third, the first two terms can dominate compression compared to the third term when when $D > k_1$. \n",
    "\n",
    "In SPAUN, $D$ is 512 and $k_1=50$, we would expect compression to be dominated by a compression of encoding and decoding weights opposed to compression in transform resource counts.\n",
    "\n",
    "Another way to look at this is to take $\\frac{1}{C}$, the compression ratio of synaptic weights over encoding weights, decoding weights and transform resource counts. In this case, the formula for compression is \n",
    "\n",
    "$$\n",
    "\\frac{1}{C} = \\frac{(6D^2 + 166.4D + 81)}{(74.2 + 59D)}k_1 + \\frac{(6D^2 + 166.4D + 81)}{(64.2 + 95D)}k_1 + \\frac{(6D^2 + 166.4D + 81)}{9D^2 + 170D + 105}k_1^2\n",
    "$$\n",
    "\n",
    "We can simplify this knowing the rate of growth of the first two terms is linear and the third term is constant with respect to $D$, getting\n",
    "\n",
    "$$\n",
    "\\frac{1}{C} = \\mathcal{O}(D)k_1 + \\mathcal{O}(D)k_1 + \\mathcal{O}(1)k_1^2\n",
    "$$\n",
    "\n",
    "Since $k_1$ is a constant, we would expect the first two terms growth rate to exceed the third term, therefore, we would expect the compression ratio of synaptic weights to encoding weights and decoding weights to exceed the compression ratio of synaptic weights to tranform resource counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "The following implements the formula's above on a SPAUN model with only the WorkingMemory module instantiated. The parameter D can be set for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "D=10\n",
    "%run build_spaun_wm_only.py -d {D}\n",
    "import nengo_brainstorm_pp as pp\n",
    "import nengo\n",
    "\n",
    "pp_model = pp.preprocess(model, find_io = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nengo_brainstorm_pp import gv_utils\n",
    "#gv_utils.gv_plot(pp_model,size=(50,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WM number of neurons =  32710\n",
      "WM number of ensembles =  656\n",
      "WM decoding weights = 33210\n",
      "WM encoding weights = 50410\n",
      "WM transform resource count= 2705\n",
      "WM number of synapses =  5862500\n",
      "WM compression ratio = 0.01472495\n",
      "WM fanout =  2381\n",
      "Avg. neurons per ensemble = 49.86\n",
      "Avg. synapses per neuron = 179.23 \n",
      "Avg. fanout = 3.63\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "k_1 = 50\n",
    "d_misc = 1\n",
    "k_2 = 20\n",
    "d_mem = 1\n",
    "d_sel = 1\n",
    "d_gate = 1\n",
    "#D = 4\n",
    "d_1 = 1\n",
    "d_ne=1\n",
    "\n",
    "###################\n",
    "# Calculating number of encoders\n",
    "###################\n",
    "def _wm_misc_blocks_num_encoders(k_1, d_misc):\n",
    "    return 0\n",
    "\n",
    "def _wm_mem_blocks_num_encoders(D, k_1, d_1, d_mem):\n",
    "    return (7 * ((2*k_1*(d_1**2)) + 2*((3*k_1*(d_1**2))+3*((D/d_1)*k_1*(d_mem**2)) \\\n",
    "                                       + 2*((D/d_1)*k_1*(d_ne**2)))))\n",
    "\n",
    "def _wm_sel_blocks_num_encoders(D,k_1, d_1, k_2, d_sel):\n",
    "    return (3 * (k_2*(d_1**2) + 2*((D/d_1)*k_1*(d_sel**2)) \\\n",
    "                 + (4*(D/d_1)*k_1*(d_ne**2))))\n",
    "\n",
    "def _wm_gate_blocks_num_encoders(D,k_1,d_1,d_gate):\n",
    "    return (7 * (D/d_1)*k_1*(d_gate**2)) + k_1*(d_gate**2)\n",
    "\n",
    "def wm_num_encoders(D,k_1,d_1,k_2,d_misc,d_mem,d_sel,d_gate):\n",
    "    return _wm_misc_blocks_num_encoders(k_1, d_misc) + \\\n",
    "        _wm_mem_blocks_num_encoders(D, k_1, d_1, d_mem) + \\\n",
    "        _wm_sel_blocks_num_encoders(D,k_1, d_1, k_2, d_sel) + \\\n",
    "        _wm_gate_blocks_num_encoders(D,k_1,d_1,d_gate)   \n",
    "        \n",
    "\n",
    "###################\n",
    "# Calculating number of decoders\n",
    "###################\n",
    "def _wm_misc_blocks_num_decoders(k_1, d_1):\n",
    "    return 3*k_1*(d_1**2)\n",
    "\n",
    "def _wm_mem_blocks_num_decoders(D, k_1, d_1, d_mem):\n",
    "    return ((63+42*(D/d_1))*k_1*d_1**2) + (D/d_1)*k_1*(d_1**2)\n",
    "\n",
    "def _wm_sel_blocks_num_decoders(D,k_1, d_1, k_2, d_sel):\n",
    "    return (3 * ((1*k_2*(d_1**2)) + 3*((D/d_1)*k_1*(d_sel**2))))\n",
    "\n",
    "def _wm_gate_blocks_num_decoders(D,k_1,d_1,d_gate):\n",
    "    return (7 * ((1*k_1*(d_1**2)) + ((D/d_1)*k_1*(d_gate**2))))\n",
    "\n",
    "def wm_num_decoders(D,k_1,d_1,k_2,d_misc,d_mem,d_sel,d_gate):\n",
    "    return _wm_misc_blocks_num_decoders(k_1, d_1) + \\\n",
    "        _wm_mem_blocks_num_decoders(D, k_1, d_1, d_mem) + \\\n",
    "        _wm_sel_blocks_num_decoders(D,k_1, d_1, k_2, d_sel) + \\\n",
    "        _wm_gate_blocks_num_decoders(D,k_1,d_1,d_gate)        \n",
    "\n",
    "###################\n",
    "# Calculating transform resource counts\n",
    "###################\n",
    "\n",
    "def wm_transform_count(D):\n",
    "    result = (212*D+9) + 3*(D**2) + 24\n",
    "    if (D<2 or D>4):\n",
    "        result += (6*(D-3)*(D-4))\n",
    "    return result\n",
    "###################\n",
    "# Calculating synaptic weights\n",
    "###################\n",
    "# Linear regression plus knowing that some subnets are 50*50 and some are 50*20; expand on this later\n",
    "\n",
    "def wm_synaptic_weights(D,k_1,d_1,k_2):\n",
    "    result = (206*D+9)*((k_1*d_1)**2) + 6*D*(k_1*d_1)*(k_2*d_1)\n",
    "    if (D<2 or D>4):\n",
    "        result += (6*(D-3)*(D-4))*((k_1*d_1)**2)\n",
    "    return result\n",
    "\n",
    "###################\n",
    "# Calculating compression ratio\n",
    "###################\n",
    "\n",
    "def wm_compression(D,k_1,d_1,k_2,d_misc,d_mem,d_sel,d_gate):\n",
    "    return (wm_num_decoders(D,k_1,d_1,k_2,d_misc,d_mem,d_sel,d_gate) \\\n",
    "            + wm_num_encoders(D,k_1,d_1,k_2,d_misc,d_mem,d_sel,d_gate) \\\n",
    "            + wm_transform_count(D)) / \\\n",
    "            float(wm_synaptic_weights(D,k_1,d_1,k_2))\n",
    "           \n",
    "###################\n",
    "# Calculating number of neurons\n",
    "###################\n",
    "def _wm_misc_blocks_num_neurons(k_1, d_misc):\n",
    "    return 3*k_1*d_misc\n",
    "\n",
    "def _wm_mem_blocks_num_neurons(D, k_1, d_1, d_mem):\n",
    "    return (7 * ((3*k_1*d_1) + 2*((3*k_1*d_1)+3*((D/d_1)*k_1*d_mem))))\n",
    "\n",
    "def _wm_sel_blocks_num_neurons(D,k_1, d_1, k_2, d_sel):\n",
    "    return (3 * ((1*k_2*d_1) + 3*((D/d_1)*k_1*d_sel)))\n",
    "\n",
    "def _wm_gate_blocks_num_neurons(D,k_1,d_1,d_gate):\n",
    "    return (7 * ((1*k_1*d_1) + ((D/d_1)*k_1*d_gate)))\n",
    "\n",
    "def wm_num_neurons(D,k_1,d_1,k_2,d_misc,d_mem,d_sel,d_gate):\n",
    "    return _wm_misc_blocks_num_neurons(k_1, d_misc) + \\\n",
    "        _wm_mem_blocks_num_neurons(D, k_1, d_1, d_mem) + \\\n",
    "        _wm_sel_blocks_num_neurons(D,k_1, d_1, k_2, d_sel) + \\\n",
    "        _wm_gate_blocks_num_neurons(D,k_1,d_1,d_gate)        \n",
    "        \n",
    "###################\n",
    "# Calculating number of ensembles\n",
    "###################\n",
    "def _wm_misc_blocks_num_ensembles():\n",
    "    return 3\n",
    "\n",
    "def _wm_mem_blocks_num_ensembles(D, d_1):\n",
    "    return 63 + 42*(D/d_1)\n",
    "\n",
    "def _wm_sel_blocks_num_ensembles(D, d_1):\n",
    "    return 3 + 9*(D/d_1)\n",
    "#    return (3 * (1 + 3*(D/d_1)))\n",
    "\n",
    "def _wm_gate_blocks_num_ensembles(D, d_1):\n",
    "    return 7 + 7*(D/d_1)\n",
    "\n",
    "def wm_num_ensembles(D,d_1):\n",
    "    return _wm_misc_blocks_num_ensembles() + \\\n",
    "        _wm_mem_blocks_num_ensembles(D,d_1) + \\\n",
    "        _wm_sel_blocks_num_ensembles(D,d_1) + \\\n",
    "        _wm_gate_blocks_num_ensembles(D,d_1)\n",
    "\n",
    "###################\n",
    "# Calculating fanout\n",
    "###################\n",
    "def wm_fanout(D,k_1,d_1,k_2):        \n",
    "    result = (212*D+9)\n",
    "    if (D<2 or D>4):\n",
    "        result += (6*(D-3)*(D-4))\n",
    "    return result\n",
    "\n",
    "N_NRN = wm_num_neurons(D,k_1,d_1,k_2,d_misc,d_mem,d_sel,d_gate)\n",
    "N_ENS = wm_num_ensembles(D,d_1)\n",
    "N_D = wm_num_decoders(D,k_1,d_1,k_2,d_misc,d_mem,d_sel,d_gate)\n",
    "N_E = wm_num_encoders(D,k_1,d_1,k_2,d_misc,d_mem,d_sel,d_gate)\n",
    "N_T = wm_transform_count(D)\n",
    "N_SYN = wm_synaptic_weights(D,k_1,d_1,k_2)\n",
    "C = wm_compression(D,k_1,d_1,k_2,d_misc,d_mem,d_sel,d_gate)\n",
    "N_FAN = wm_fanout(D,k_1,d_1,k_2)\n",
    "R_NRN_ENS = float(N_NRN/float(N_ENS))\n",
    "R_SYN_NRN = float(N_SYN/float(N_NRN))\n",
    "R_FAN_ENS = float(N_FAN/float(N_ENS))\n",
    "print \"WM number of neurons = \",N_NRN\n",
    "print \"WM number of ensembles = \", N_ENS\n",
    "print \"WM decoding weights =\", N_D\n",
    "print \"WM encoding weights =\", N_E\n",
    "print \"WM transform resource count=\", N_T\n",
    "print \"WM number of synapses = \", N_SYN\n",
    "print \"WM compression ratio = %.8f\" % C\n",
    "print \"WM fanout = \", N_FAN\n",
    "print \"Avg. neurons per ensemble = %.2f\" % R_NRN_ENS\n",
    "print \"Avg. synapses per neuron = %.2f \" % R_SYN_NRN\n",
    "print \"Avg. fanout = %.2f\" % R_FAN_ENS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Verification\n",
    "We now want to verify that the results from our formulas are correct. To verify correctness, we use the compute_stats function which calculates the values we are interested in by counting the number of relevant elements for each statistic. For example, to determine the number of ensembles, the compute_stats function simply counts the number of ensembles in the model. In another example, to determine the total number of synapses in the model, the function evaluates each ensemble determining the list of ensembles connected to the given ensemble (the fanout). After determining the fanout, the function computes the synaptic weights between the ensemble and each ensemble it is connected to. The function repeats this for each ensemble.\n",
    "\n",
    "The compute_stats function returns a dictionary of values corresponding to the values we computed using this notebooks formulas. The formulas results are compared to the dictionary values in the compare_stats function. The compare_stats function will tell if the formula results and dictionary values are equal (or approximately equal in the case of ratios) which would indicate that the formulas are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed\n"
     ]
    }
   ],
   "source": [
    "import compute_stats as cp\n",
    "stats = cp.compute_stats(pp_model,print_results=False)\n",
    "def compare_stats(N_NRN, N_ENS, N_D, N_E, N_T, N_SYN, C, N_FAN, R_NRN_ENS, R_SYN_NRN, R_FAN_ENS, stats):\n",
    "    all_passed = True\n",
    "    if (abs(N_NRN - stats['N_NRN']) > 0):\n",
    "        print \"N_NRN test fails\"\n",
    "        all_passed = False      \n",
    "    if (abs(N_ENS - stats['N_ENS']) > 0):\n",
    "        print \"N_ENS test fails\"\n",
    "        all_passed = False    \n",
    "    if (abs(N_D - stats['N_D']) > 0):\n",
    "        print \"N_D test fails\"\n",
    "        all_passed = False    \n",
    "    if (abs(N_E - stats['N_E']) > 0):\n",
    "        print \"N_E test fails\"\n",
    "        all_passed = False    \n",
    "    if (abs(N_T - stats['N_T']) > 0):\n",
    "        print \"N_T test fails\"\n",
    "        all_passed = False    \n",
    "    if (abs(N_SYN - stats['N_SYN']) > 0):\n",
    "        print \"N_SYN test fails\"\n",
    "        all_passed = False    \n",
    "    if (abs(C - stats['C']) > 0.00001):\n",
    "        print \"C test fails\"\n",
    "        all_passed = False    \n",
    "    if (abs(N_FAN - stats['N_FAN']) > 0):\n",
    "        print \"N_FAN test fails\"\n",
    "        all_passed = False    \n",
    "    if (abs(R_NRN_ENS - stats['R_NRN_ENS']) > 0.00001):\n",
    "        print \"R_NRN_ENS test fails\"\n",
    "        all_passed = False    \n",
    "    if (abs(R_SYN_NRN - stats['R_SYN_NRN']) > 0.00001):\n",
    "        print \"R_SYN_NRN test fails\"\n",
    "        all_passed = False    \n",
    "    if (abs(R_FAN_ENS - stats['R_FAN_ENS']) > 0.00001):\n",
    "        print \"R_FAN_ENS test fails\"\n",
    "        all_passed = False    \n",
    "        \n",
    "    if all_passed:\n",
    "        print \"All tests passed\"\n",
    "    else:\n",
    "        print \"Some tests failed\"\n",
    "        \n",
    "compare_stats(N_NRN, N_ENS, N_D, N_E, N_T, N_SYN, C, N_FAN, R_NRN_ENS, R_SYN_NRN, R_FAN_ENS, stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the tests passed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "## Derivations for WorkingMemory module equations\n",
    "### Total decoding weights\n",
    "\n",
    "$$\n",
    "N_\\text{D} = 3k_1d_1^2 + (63 + \\frac{42D}{d_1}) \\cdot k_1d_1^2 + \\frac{D}{d_1}k_1d_1^2 + 3k_2d_1^2 + \\frac{9D}{d_1}k_1d_1^2 + 7k_1d_1^2 + \\frac{7D}{d_1}k_1d_1^2\n",
    "$$\n",
    "\n",
    "The first term is the number of encoding weights from the two miscellaneous blocks. THe second and third terms are from the memory blocks. The fourth and fifth terms are from selector blocks and the last two terms are from the gate blocks.\n",
    "\n",
    "### Total encoding weights\n",
    "    \n",
    "$$\n",
    "N_\\text{E} = 14k_1d_1^2 + 42k_1d_1^2 + \\frac{42D}{d_1}k_1d_1^2 + \\frac{28D}{d_1}k_1d_1^2 + 3k_2d_1^2 + \\frac{6D}{d_1}k_1d_1^2 + \\frac{12D}{d_1}k_1d_1^2 + \\frac{7D}{d_1}k_1d_1^2 + k_1d_1^2\n",
    "$$\n",
    "\n",
    "The first term is the number of encoding weights from the two miscellaneous blocks. THe second and third terms are from the memory blocks. The fourth and fifth terms are from selector blocks and the last two terms are from the gate blocks.\n",
    "\n",
    "### Total number of neurons\n",
    "    \n",
    "$$\n",
    "N_\\text{NRN} = \n",
    "3k_1d_1 + 63k_1d_1 + \\frac{42D}{d_1}k_1d_1 + 3k_2d_1 + \\frac{3D}{d_1}k_1d_1 + 7k_1d_1 + \\frac{7D}{d_1}k_1d_1\n",
    "$$\n",
    "\n",
    "The first term is the number of neurons from the two miscellaneous blocks. THe second and third terms are from the memory blocks. The fourth and fifth terms are from selector blocks and the last two terms are from the gate blocks.\n",
    "\n",
    "### Total number of ensembles\n",
    "\n",
    "$$\n",
    "N_\\text{ENS} = 3 + 63 + \\frac{42D}{d_1} + 3 + \\frac{9D}{d_1} + 7 + \\frac{7D}{d_1}\n",
    "$$\n",
    "\n",
    "The first term is the number of ensembles from the two miscellaneous blocks. THe second and third terms are from the memory blocks. The fourth and fifth terms are from selector blocks and the last two terms are from the gate blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Repo's used\n",
    "The following repo versions were used when calculating these numbers:<br>\n",
    "\n",
    "github.com:Stanford-BIS/spaun2.0.git<br>\n",
    "SHA ID: 717c92f3e52641dc4e5e03ddc4d17e9934f8982f\n",
    "\n",
    "\n",
    "github.com:ctn-waterloo/nef-chip-hardware.git<br>\n",
    "SHA ID: a0a7cd470b5f0ca12c68de35ec0b28f437526bba\n",
    "\n",
    "github.com:nengo/nengo.git<br>\n",
    "SHA ID: a4e6cb6196e99b14d4165fab692d6b8eaab610cf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
